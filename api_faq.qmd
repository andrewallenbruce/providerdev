---
title: "API FAQ"
editor_options: 
   chunk_output_type: console
---

```{r setup}
#| echo: false
#| message: false
#| warning: false
source("_common.R")

htmltools::tagList(
  btn_link("https://data.cms.gov/api-docs", "CMS API Docs"),
  btn_link("https://data.cms.gov/sites/default/files/2024-10/7ef65521-65a4-41ed-b600-3a0011f8ec4b/API%20Guide%20Formatted%201_6.pdf", 
           "API FAQ"))
```

<style>
.codeblock-label {
  color: #000;
  display: inline-block;
  border-top-left-radius: .5rem;
  border-top-right-radius: .5rem;
  padding: 0.25rem 0.75rem;
  background-color: #cccccc;
  margin-bottom: 0;
  font-size: 0.875em;
  font-family: var(--bs-font-monospace);
}
  
.codeblock-label + div.sourceCode {
  margin-top: 0;
}
</style>

The **data.CMS.gov/data.json** API:

   * offers access to CMS public data
   * is REST-ful
   * has predictable resource-oriented URLs
   * accepts form-encoded requests
   * returns JSON & JSON:API responses
   * uses standard HTTP response codes.

## API Integration

To integrate endpoint requests with the **data.cms.gov Public API**, follow these steps:

   1. Dataset & Identifier: 
      * [Search for dataset](https://data.cms.gov/search) and visit its **Overview** page
      * Click **Access API** then **API Docs for the Dataset**
   2. Endpoint structure:
      * `data.cms.gov/data-api/v1/dataset/{{dataset_id}}/data` 
   3. System uses **JSON:API** query syntax:
      * Key-values: `?filter[field_name]=value&filter[field_other]=value`
      * Responses are paged and support a max page size of 5000 rows
      * Use `size` & `offset` query parameters to page through the data

--------------------------------------------------------------------------------

# Data Catalog file

The [`data.json`](https://data.cms.gov/data.json) file is an [**Open Data**](https://resources.data.gov/resources/dcat-us/) catalog containing all available datasets. As new data is added, `data.json` is automatically updated.


```{r}
#| label: data_json
data_json <- read_json_arrow(
  file = "https://data.cms.gov/data.json",
  col_select = c("dataset"),
    as_data_frame = TRUE) |> 
  to_duckdb()

data_json |> glimpse()
```


> **Note:** Removing `col_select = c("dataset")` from the above call returns the following metadata:


```{r}
#| label: col_select_remove
#| echo: false
c("@context    <chr> https://project-open-data.cio.gov/v1.1/schema/catalog.jsonld", 
  "@id         <chr> https://data.cms.gov/data.json", 
  "@type       <chr> dcat:Catalog", 
  "conformsTo  <chr> https://project-open-data.cio.gov/v1.1/schema", 
  "describedBy <chr> https://project-open-data.cio.gov/v1.1/schema/catalog.json", 
  "dataset     <list> [<data.frame[138 x 22]>]") |> 
  cat(sep = "\n")
```


Within `data.json`, there is an array called `dataset`. One can search through this array using the dataset's `title`, such as `"Payroll Based Journal Daily Nurse Staffing"`:


```{r}
#| label: dataset_title
data_json |> 
  pull(dataset) |> 
  pluck(1) |> 
  filter(
    grepl(
      "Payroll Based Journal Daily Nurse Staffing", 
      title)) |> 
  mutate(
    bureauCode = delist(bureauCode),
    keyword = flatten_column(keyword),
    language = delist(language),
    programCode = delist(programCode),
    references = delist(references),
    theme = delist(theme)) |> 
  unnest_wider(contactPoint, names_sep = "_") |>
  unnest_wider(publisher, names_sep = "_") |>
  rename_with(remove_at_symbol) |> 
  purse()
```


Within `dataset`, there is an array called `distribution` which contains all dataset versions, in all available formats:


```{r}
#| label: distribution
distribution <- data_json |> 
  pull(dataset) |> 
  pluck(1) |> 
  select(distribution) |> 
  unnest(distribution) |> 
  rename_with(remove_at_symbol)

distribution |> 
  purse()
```

## Formats

   * __description__ `"latest"` is a URL that always point to the latest data
   * __mediaType__ `"text/csv"` is a downloadable CSV file
   * __mediaType__ `"application/zip"` is a downloadable ZIP file
   * __format__ `"API"` is an API endpoint
   * Remaining entries provide references to data at fixed points in time

```{r}
distribution |> 
  count(description, 
        format, 
        mediaType) |> 
  emphatic::as_emphatic() |> 
  emphatic::hl(ggplot2::scale_colour_viridis_c(), cols = "n") |>
  emphatic::hl_adjust(text_contrast = 0.5, na = "-")
```

For instance, the following URL will *always* point to the **Q2 2021 Payroll Based Journal Daily Nurse Staffing** data:

```{r}
#| label: staffing
# "https://data.cms.gov/data-api/v1/dataset/d10d792e-ea6e-4145-8512-34efbc1be04b/data"

staffing <- distribution |> 
  filter(
    grepl("Payroll Based Journal Daily Nurse Staffing", title),
    format == "API",
    grepl("^2021-04", temporal)) |> 
  pull(accessURL) |> 
  request() |> 
  req_perform() |> 
  resp_body_json(simplifyVector = TRUE)

head(staffing, 1) |> 
  purse()
```

## Temporal Data

Datasets with multiple historical versions available will have a `temporal` field in the `distribution` array of the `data.json`.

> **Format**: `YYYY-mm-dd/YYYY-mm-dd`

The following example returns the [2017 Medicare Inpatient Hospitals - by Provider and Service Data](https://data.cms.gov/provider-summary-by-type-of-service/medicare-inpatienthospitals/medicare-inpatient-hospitals-by-provider-and-service):

```{r}
#| label: temporal_data
distribution |> 
  filter(
    grepl("Medicare Inpatient Hospitals - by Provider and Service", title), 
    format == "API",
    temporal == "2017-01-01/2017-12-31") |> 
  purse()
```

## Different JSON Methods

There are two methods of accessing the latest data. 

Both result in a URL pointing to the most recent version of the dataset. This URL is canonical, i.e., will not change as new versions are added. 

> For this reason, it is _recommended to **always** start with the **`data.json` object** as opposed to hardcoding any URL_.

### Standard JSON

Use the __`distribution`__ with the `"latest"` __`description`__:

```r
<data_json>
    => <dataset> 
    => <distribution> 
    -> ($description == "latest")
    -> ($accessURL)
```

> For example, this URL for Opt Out Affidavits is:

```r
https://data.cms.gov/
   data-api/v1/dataset/
   9887a515-7552-4693-bf58-735c77af46d7/
   data
   ^^^^
```


```{r}
#| label: json_standard
distribution |> 
  filter(
    grepl("Order and Referring", title),
    description == "latest") |> 
  purse()
```

### JSON:API

The **JSON:API** form has a slightly different structure that includes metadata about the dataset. Otherwise it is identical to the **Standard JSON** method. 

Use the URL in the `identifier` field. 


```r
<data_json>
    => <dataset> 
    -> ($title == "Order and Referring")
    -> ($identifier)
```

> For example, this URL for Opt Out Affidavits is:

```r
https://data.cms.gov/
   data-api/v1/dataset/
   9887a515-7552-4693-bf58-735c77af46d7/
   data-viewer
   ^^^^^^^^^^^
```

```{r}
#| label: json_api
json_api <- data_json |> 
  pull(dataset) |> 
  pluck(1) |> 
  tibble() |> 
  filter(
    grepl(
      "Order and Referring", 
      title))

json_api |> 
  mutate(
    bureauCode = delist(bureauCode),
    keyword = flatten_column(keyword),
    language = delist(language),
    programCode = delist(programCode),
    references = delist(references),
    theme = delist(theme)) |> 
  unnest_wider(contactPoint, names_sep = "_") |>
  unnest_wider(publisher, names_sep = "_") |> 
  purse()
```

--------------------------------------------------------------------------------

# Pagination

The default is to provide the first 1,000 rows per request. However, there is an ability to increase the limit to 5,000 rows per request. You can use pagination to retrieve the entire dataset. 

For example, with the Opt Out Affidavits dataset:

   1. Start with the following request to get the number of rows:

```{r}
#| label: pagination_1
stats <- request("https://data.cms.gov/data-api/v1/dataset/9887a515-7552-4693-bf58-735c77af46d7/data/stats") |>
  req_perform() |> 
  resp_body_json(simplifyVector = TRUE)

stats |> purse()
```
      
   2. Make a request for the *first* 5,000 rows:
      
```{r}
#| label: pagination_2
request("https://data.cms.gov/data-api/v1/dataset/9887a515-7552-4693-bf58-735c77af46d7/data?size=5000&offset=0") |>
  req_perform() |> 
  resp_body_json(simplifyVector = TRUE) |> 
  tibble() |> 
  purse()
```
      
   3. Make a request for the *next* 5,000 rows:
   
```{r}
#| label: pagination_3
request("https://data.cms.gov/data-api/v1/dataset/9887a515-7552-4693-bf58-735c77af46d7/data?size=5000&offset=5000") |>
  req_perform() |> 
  resp_body_json(simplifyVector = TRUE) |> 
  tibble() |> 
  purse()
```

   4. Continue increasing the offset until you reach the count from step 1

```{r}
#| label: pagination_4
request("https://data.cms.gov/data-api/v1/dataset/9887a515-7552-4693-bf58-735c77af46d7/data?size=5000&offset=10000") |>
  req_perform() |> 
  resp_body_json(simplifyVector = TRUE) |> 
  tibble() |> 
  purse()
```

## Pagination Example

Paginates through the [Opt Out Affidavits](https://data.cms.gov/provider-characteristics/medicare-provider-supplier-enrollment/opt-out-affidavits) data:

::: callout

## Find the Number of Rows

Use the `stats` endpoints i.e., 

   * `/data-viewer/stats`
   * `/data/stats`

::: 


```r
data/stats?
   filter[f1][path]=State Code&
   filter[f1][value]=GA

data?
   size=5&
   filter[f1][path]=State Code&
   filter[f1][value]=GA
```

```{r}
#| label: pagination_optout
# offset_sequence <- \(found = 47500, limit = 5000) {
#   
#   if (found <= limit) return(found)
#   
#   if ((found %% 10) == 0) found else (found + (limit - found))
#   
#   seq.int(
#     from = 0, 
#     to = if ((found %% 5) == 0) found else (limit + found), 
#     by = limit)
# }

# Not working
# offset_sequence(found = 47025)

query <- glue::glue(
  'list(
  "filter[id-{FID}][path]" = "{PATH}",
  "filter[id-{FID}][value]" = "{VALUE}"
  )', 
  FID = 1, 
  PATH = "State Code", 
  VALUE = "GA") |> 
  rlang::parse_expr() |> 
  rlang::eval_bare()

accessURL <- distribution |> 
  filter(
    grepl("Opt Out Affidavits : ", title), 
    format == "API",
    description == "latest") |> 
  pull(accessURL) |> 
  request() |> 
  req_url_query(size = 5000, !!!query)

resp_found <- accessURL |> 
  req_url_path_append("stats") |> 
  req_perform() |> 
  resp_body_json() |> 
  fuimus::gelm("found")

accessURL |> 
  req_perform() |> 
  resp_body_json(simplifyVector = TRUE) |> 
  tibble() |> 
  purse()
```


# CSVs

   1. Start with a request to the `data.json`. 
   2. Match the dataset `title` with its name.
   3. The most recent release will be at the top of the `distribution` array. 
   4. There is also a `temporal` field which can be used to find earlier releases.
   5. Datasets available as either CSV or ZIP files will be designated as such in the `mediaType` field.
   6. The `downloadURL` field will provide a direct download link for the data.

```{r}
#| label: csv_download
orderrefer_url <- distribution |> 
  filter(
    grepl("Order and Referring", title), 
    mediaType == "text/csv",
    modified == max(modified)) |> 
  pull(downloadURL)
  
orderrefer_csv <- read_csv_arrow(
  file = orderrefer_url, 
  as_data_frame = TRUE) |> 
  to_duckdb()

# approx 2 million rows
orderrefer_csv
```

::: callout

## ZIP Example

_CMS Summary Statistics/COVID data -> Likely not relevant to package scope_

::: 

# _New:_ **Resources**

Resources (supplemental documents to the main dataset) are now available for download through the public API. Included are sub-files, tables, supplementary data, reports, and documentation. The new endpoints appear in the `resourcesAPI` field, a secondary endpoint from `data.json`. 

> **Note**: Limit by the `name` of the resource you want to download. This name may change between versions.

## Example: Reassignment SubFile (`csv`)

Site: [Public Provider Enrollment Reassignment SubFile](https://data.cms.gov/provider-characteristics/medicare-provider-supplier-enrollment/medicare-fee-for-service-public-provider-enrollment)

```{r}
#| label: add_resources
resp_resources <- distribution |> 
  filter(
  grepl("Medicare Fee-For-Service", title),
  description == "latest") |> 
  pull(resourcesAPI) |> 
  request() |> 
  req_perform() |> 
  resp_body_json(simplifyVector = FALSE) |> 
  list_flatten() |> 
  list_flatten()

reassign_url <- tibble(
  name = gelm(resp_resources, "name$") |> delist(),
  size = gelm(resp_resources, "fileSize$") |> delist(),
  url =  gelm(resp_resources, "downloadURL$") |> delist()) |> 
  filter(grepl("Reassignment", name))

reassign_url |> 
  purse()

reassign_csv <- read_csv_arrow(
  file = reassign_url$url, 
  as_data_frame = TRUE) |> 
  to_duckdb()

reassign_csv
```

-------------------------------------------------------------------------------

## Schema

```r
[data.json]
 |--@context
 |--@id
 |--@type
 |--conformsTo
 |--describedBy
 |--[dataset]
     |--@type
     |--accessLevel
     |--accrualPeriodicity
     |--bureauCode
     |--[contactPoint]
          |--@type
          |--fn
          |--hasEmail
     |--describedBy
     |--dataQuality
     |--description
     |--identifier
     |--[keyword]
     |--landingPage
     |--language
     |--license
     |--modified
     |--programCode
     |--[publisher]
          |--@type
          |--name
     |--references
     |--temporal
     |--theme
     |--title
     |--describedByType
     |--[distribution]
         |--@type
         |--format
         |--accessURL
         |--resourcesAPI
         |--description
         |--title
         |--modified
         |--temporal
         |--downloadURL
         |--mediaType
```
